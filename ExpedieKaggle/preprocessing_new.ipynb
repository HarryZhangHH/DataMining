{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# from imblearn.combine import SMOTETomek\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan(df, method):\n",
    "    for col in df.columns:\n",
    "        \n",
    "        prc_nan = df[col].isnull().sum() / len(df[col])\n",
    "        \n",
    "        if col in ['srch_query_affinity_score']:\n",
    "            print('Preserved {} with {:.2f} % missing'.format(col, prc_nan * 100))\n",
    "            continue\n",
    "        # Impute with median or mean\n",
    "        if prc_nan < .7:\n",
    "            print('Preserved {} with {:.2f} % missing'.format(col, prc_nan * 100))\n",
    "            if method == 'median':\n",
    "                if col != 'date_time': df[col] = df[col].fillna(df[col].median())\n",
    "            elif method == 'mean':\n",
    "                if col != 'date_time': df[col] = df[col].fillna(df[col].mean())\n",
    "            elif method == 'zero':\n",
    "                df[col] = df[col].fillna(0)\n",
    "        # Drop if more than 50% missing\n",
    "        else:\n",
    "            print('Dropped {} with {:.2f} % missing'.format(col, prc_nan * 100))\n",
    "            df = df.drop([col], axis=1)\n",
    "    return df\n",
    "\n",
    "def initial_clean(df):\n",
    "    # We made a boolean variable indicating whether the user performing the query had any purchase history or not. \n",
    "    df['srch_hist_bool'] = 0\n",
    "    df['srch_hist_bool'][~df.visitor_hist_adr_usd.isnull()] = 1\n",
    "    # Handle missing values\n",
    "    df[['visitor_hist_adr_usd', 'visitor_hist_starrating']] = df[['visitor_hist_adr_usd', 'visitor_hist_starrating']].fillna(0)\n",
    "    df_cleaned = fill_nan(df, ' ')\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preserved srch_id with 0.00 % missing\n",
      "Preserved date_time with 0.00 % missing\n",
      "Preserved site_id with 0.00 % missing\n",
      "Preserved visitor_location_country_id with 0.00 % missing\n",
      "Preserved visitor_hist_starrating with 0.00 % missing\n",
      "Preserved visitor_hist_adr_usd with 0.00 % missing\n",
      "Preserved prop_country_id with 0.00 % missing\n",
      "Preserved prop_id with 0.00 % missing\n",
      "Preserved prop_starrating with 0.00 % missing\n",
      "Preserved prop_review_score with 0.15 % missing\n",
      "Preserved prop_brand_bool with 0.00 % missing\n",
      "Preserved prop_location_score1 with 0.00 % missing\n",
      "Preserved prop_location_score2 with 21.99 % missing\n",
      "Preserved prop_log_historical_price with 0.00 % missing\n",
      "Preserved position with 0.00 % missing\n",
      "Preserved price_usd with 0.00 % missing\n",
      "Preserved promotion_flag with 0.00 % missing\n",
      "Preserved srch_destination_id with 0.00 % missing\n",
      "Preserved srch_length_of_stay with 0.00 % missing\n",
      "Preserved srch_booking_window with 0.00 % missing\n",
      "Preserved srch_adults_count with 0.00 % missing\n",
      "Preserved srch_children_count with 0.00 % missing\n",
      "Preserved srch_room_count with 0.00 % missing\n",
      "Preserved srch_saturday_night_bool with 0.00 % missing\n",
      "Preserved srch_query_affinity_score with 93.60 % missing\n",
      "Preserved orig_destination_distance with 32.43 % missing\n",
      "Preserved random_bool with 0.00 % missing\n",
      "Dropped comp1_rate with 97.58 % missing\n",
      "Dropped comp1_inv with 97.39 % missing\n",
      "Dropped comp1_rate_percent_diff with 98.10 % missing\n",
      "Preserved comp2_rate with 59.17 % missing\n",
      "Preserved comp2_inv with 57.04 % missing\n",
      "Dropped comp2_rate_percent_diff with 88.78 % missing\n",
      "Preserved comp3_rate with 69.06 % missing\n",
      "Preserved comp3_inv with 66.70 % missing\n",
      "Dropped comp3_rate_percent_diff with 90.46 % missing\n",
      "Dropped comp4_rate with 93.80 % missing\n",
      "Dropped comp4_inv with 93.07 % missing\n",
      "Dropped comp4_rate_percent_diff with 97.36 % missing\n",
      "Preserved comp5_rate with 55.18 % missing\n",
      "Preserved comp5_inv with 52.40 % missing\n",
      "Dropped comp5_rate_percent_diff with 83.04 % missing\n",
      "Dropped comp6_rate with 95.16 % missing\n",
      "Dropped comp6_inv with 94.74 % missing\n",
      "Dropped comp6_rate_percent_diff with 98.06 % missing\n",
      "Dropped comp7_rate with 93.64 % missing\n",
      "Dropped comp7_inv with 92.81 % missing\n",
      "Dropped comp7_rate_percent_diff with 97.21 % missing\n",
      "Preserved comp8_rate with 61.34 % missing\n",
      "Preserved comp8_inv with 59.92 % missing\n",
      "Dropped comp8_rate_percent_diff with 87.60 % missing\n",
      "Preserved click_bool with 0.00 % missing\n",
      "Dropped gross_bookings_usd with 97.21 % missing\n",
      "Preserved booking_bool with 0.00 % missing\n",
      "Preserved srch_hist_bool with 0.00 % missing\n"
     ]
    }
   ],
   "source": [
    "# Clean training set\n",
    "df = pd.read_csv('../training_set_VU_DM.csv')\n",
    "df_cleaned = initial_clean(df)\n",
    "df_cleaned.to_csv('data/training_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preserved srch_id with 0.00 % missing\n",
      "Preserved date_time with 0.00 % missing\n",
      "Preserved site_id with 0.00 % missing\n",
      "Preserved visitor_location_country_id with 0.00 % missing\n",
      "Preserved visitor_hist_starrating with 0.00 % missing\n",
      "Preserved visitor_hist_adr_usd with 0.00 % missing\n",
      "Preserved prop_country_id with 0.00 % missing\n",
      "Preserved prop_id with 0.00 % missing\n",
      "Preserved prop_starrating with 0.00 % missing\n",
      "Preserved prop_review_score with 0.15 % missing\n",
      "Preserved prop_brand_bool with 0.00 % missing\n",
      "Preserved prop_location_score1 with 0.00 % missing\n",
      "Preserved prop_location_score2 with 21.94 % missing\n",
      "Preserved prop_log_historical_price with 0.00 % missing\n",
      "Preserved price_usd with 0.00 % missing\n",
      "Preserved promotion_flag with 0.00 % missing\n",
      "Preserved srch_destination_id with 0.00 % missing\n",
      "Preserved srch_length_of_stay with 0.00 % missing\n",
      "Preserved srch_booking_window with 0.00 % missing\n",
      "Preserved srch_adults_count with 0.00 % missing\n",
      "Preserved srch_children_count with 0.00 % missing\n",
      "Preserved srch_room_count with 0.00 % missing\n",
      "Preserved srch_saturday_night_bool with 0.00 % missing\n",
      "Preserved srch_query_affinity_score with 93.58 % missing\n",
      "Preserved orig_destination_distance with 32.44 % missing\n",
      "Preserved random_bool with 0.00 % missing\n",
      "Dropped comp1_rate with 97.66 % missing\n",
      "Dropped comp1_inv with 97.48 % missing\n",
      "Dropped comp1_rate_percent_diff with 98.18 % missing\n",
      "Preserved comp2_rate with 59.35 % missing\n",
      "Preserved comp2_inv with 57.23 % missing\n",
      "Dropped comp2_rate_percent_diff with 88.84 % missing\n",
      "Preserved comp3_rate with 69.25 % missing\n",
      "Preserved comp3_inv with 66.91 % missing\n",
      "Dropped comp3_rate_percent_diff with 90.50 % missing\n",
      "Dropped comp4_rate with 93.69 % missing\n",
      "Dropped comp4_inv with 92.97 % missing\n",
      "Dropped comp4_rate_percent_diff with 97.32 % missing\n",
      "Preserved comp5_rate with 55.20 % missing\n",
      "Preserved comp5_inv with 52.40 % missing\n",
      "Dropped comp5_rate_percent_diff with 83.06 % missing\n",
      "Dropped comp6_rate with 95.11 % missing\n",
      "Dropped comp6_inv with 94.69 % missing\n",
      "Dropped comp6_rate_percent_diff with 98.04 % missing\n",
      "Dropped comp7_rate with 93.63 % missing\n",
      "Dropped comp7_inv with 92.81 % missing\n",
      "Dropped comp7_rate_percent_diff with 97.19 % missing\n",
      "Preserved comp8_rate with 61.64 % missing\n",
      "Preserved comp8_inv with 60.22 % missing\n",
      "Dropped comp8_rate_percent_diff with 87.68 % missing\n",
      "Preserved srch_hist_bool with 0.00 % missing\n"
     ]
    }
   ],
   "source": [
    "# Clean test set\n",
    "df = pd.read_csv('../test_set_VU_DM.csv')\n",
    "df_cleaned = initial_clean(df)\n",
    "df_cleaned.to_csv('data/test_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/training_cleaned.csv')\n",
    "df_test = pd.read_csv('data/test_cleaned.csv')\n",
    "\n",
    "# all_list = ['visitor_location_country_id', 'prop_country_id', 'site_id', 'prop_id','prop_starrating', 'prop_review_score', \\\n",
    "#     'prop_location_score1', 'prop_location_score2', 'prop_brand_bool', 'price_usd', 'srch_destination_id', \\\n",
    "#     'orig_destination_distance', 'srch_length_of_stay', 'random_bool', 'promotion_flag']\n",
    "df_all = pd.concat([df_train, df_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-way count of the feature in the combine of train and test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion of prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Find outlier of all night price for price_usd\n",
    "'''\n",
    "price_list = ['price_usd', 'prop_country_id', 'srch_length_of_stay']\n",
    "df_price_all = pd.concat([df_train[price_list], df_test[price_list]], ignore_index=True)\n",
    "df_price_all['price_per_night'] =  df_price_all.price_usd / df_price_all.srch_length_of_stay\n",
    "df_country_price = df_price_all.groupby('prop_country_id')['price_per_night'].agg('mean').to_frame('price_mean_per_country')\n",
    "df_country_outlier_id = df_country_price[df_country_price.price_mean_per_country > (df_country_price.price_mean_per_country.mean() + df_country_price.price_mean_per_country.std())]\n",
    "df_country_price = df_country_price.drop(df_country_outlier_id.index.values.tolist())\n",
    "df_country_outlier_id_2 = df_country_price[df_country_price.price_mean_per_country > (df_country_price.price_mean_per_country.mean() + 2*df_country_price.price_mean_per_country.std())]\n",
    "df_country_outlier_id = pd.concat([df_country_outlier_id.reset_index(), df_country_outlier_id_2.reset_index()], ignore_index=True)\n",
    "df_country_outlier_id.to_csv('data/price_outlier_country_id.csv')\n",
    "\n",
    "'''\n",
    "Drop price_usd outliers\n",
    "'''\n",
    "mask = df_all.prop_country_id.isin(df_country_outlier_id.prop_country_id.to_list())\n",
    "df_all.price_usd[mask] /= df_all.srch_length_of_stay[mask]\n",
    "drop_mask = (df_all.price_usd > 100000.0) | (df_all.price_usd == 0.0)\n",
    "df_all.drop(df_all[drop_mask].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference of missing data\n",
    "\n",
    "Impute orig_destination_distance, prop_location_score2, prop_review_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                     9916106\n",
       "srch_id                        9916106\n",
       "date_time                      9916106\n",
       "site_id                        9916106\n",
       "visitor_location_country_id    9916106\n",
       "visitor_hist_starrating        9916106\n",
       "visitor_hist_adr_usd           9916106\n",
       "prop_country_id                9916106\n",
       "prop_id                        9916106\n",
       "prop_starrating                9916106\n",
       "prop_review_score              9901480\n",
       "prop_brand_bool                9916106\n",
       "prop_location_score1           9916106\n",
       "prop_location_score2           7738075\n",
       "prop_log_historical_price      9916106\n",
       "position                       4957546\n",
       "price_usd                      9916106\n",
       "promotion_flag                 9916106\n",
       "srch_destination_id            9916106\n",
       "srch_length_of_stay            9916106\n",
       "srch_booking_window            9916106\n",
       "srch_adults_count              9916106\n",
       "srch_children_count            9916106\n",
       "srch_room_count                9916106\n",
       "srch_saturday_night_bool       9916106\n",
       "srch_query_affinity_score       635535\n",
       "orig_destination_distance      8434539\n",
       "random_bool                    9916106\n",
       "comp2_rate                     4040050\n",
       "comp2_inv                      4250921\n",
       "comp3_rate                     3058780\n",
       "comp3_inv                      3291666\n",
       "comp5_rate                     4443481\n",
       "comp5_inv                      4719951\n",
       "comp8_rate                     3818659\n",
       "comp8_inv                      3959966\n",
       "click_bool                     4957546\n",
       "booking_bool                   4957546\n",
       "srch_hist_bool                 9916106\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Impute orig_destination_distance by matrix between pairwise distances btw countries\n",
    "'''\n",
    "df_orig_destination_distance = df_all.groupby(['visitor_location_country_id', 'prop_country_id'])['orig_destination_distance'].agg('mean').to_frame('orig_destination_distance_mean')\n",
    "df_orig_destination_distance = df_orig_destination_distance[~df_orig_destination_distance.orig_destination_distance_mean.isnull()].reset_index()\n",
    "df_all = pd.merge(df_all,df_orig_destination_distance, on=['visitor_location_country_id', 'prop_country_id'], how='left')\n",
    "df_all['orig_destination_distance'].fillna(df_all['orig_destination_distance_mean'], inplace=True)\n",
    "df_all.drop(columns=['orig_destination_distance_mean'],inplace=True)\n",
    "df_all.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train LR for prop_location_score2\n",
      "Shape of Train (7738075, 2) and label (7738075,)\n",
      "Train LR for prop_review_score\n",
      "Shape of Train (9901480, 5) and label (9901480,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Impute prop_location_score2 by Linear Regression\n",
    "'''\n",
    "df_prop_location_score2 = df_all[['prop_location_score1', 'prop_location_score2', 'price_usd']]\n",
    "df_prop_location_score2_train = df_prop_location_score2.dropna()\n",
    "X = df_prop_location_score2_train[['prop_location_score1', 'price_usd']].to_numpy()\n",
    "y = df_prop_location_score2_train['prop_location_score2'].to_numpy()\n",
    "print('Train LR for prop_location_score2')\n",
    "print(f'Shape of Train {X.shape} and label {y.shape}')\n",
    "reg_prop_location_score2 = LinearRegression().fit(X,y)\n",
    "\n",
    "pred = df_all[['prop_location_score1', 'price_usd']].to_numpy()\n",
    "pred_y = reg_prop_location_score2.predict(pred)\n",
    "df_all['prop_location_score2_pred'] = pred_y\n",
    "df_all['prop_location_score2'].fillna(df_all['prop_location_score2_pred'], inplace=True)\n",
    "\n",
    "\n",
    "'''\n",
    "Impute prop_review_score by Linear Regression\n",
    "'''\n",
    "df_prop_review_score = df_all[['prop_review_score','prop_starrating', 'prop_location_score1', 'prop_location_score2', 'price_usd', 'prop_brand_bool']]\n",
    "df_prop_review_score_train = df_prop_review_score.dropna()\n",
    "X = df_prop_review_score_train.drop(columns=['prop_review_score']).to_numpy()\n",
    "y = df_prop_review_score_train['prop_review_score'].to_numpy()\n",
    "print('Train LR for prop_review_score')\n",
    "print(f'Shape of Train {X.shape} and label {y.shape}')\n",
    "reg_prop_review_score = LinearRegression().fit(X,y)\n",
    "\n",
    "pred = df_all[['prop_starrating', 'prop_location_score1', 'prop_location_score2', 'price_usd', 'prop_brand_bool']].to_numpy()\n",
    "pred_y = reg_prop_review_score.predict(pred)\n",
    "df_all['prop_review_score_pred'] = pred_y\n",
    "df_all['prop_review_score'].fillna(df_all['prop_review_score_pred'], inplace=True)\n",
    "\n",
    "df_all.drop(columns=['prop_location_score2_pred', 'prop_review_score_pred'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction of new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rename_df_col(df):\n",
    "#     for col in df.columns:\n",
    "#         col_name = '_'.join(col)\n",
    "#         col_name = col_name.replace(\"(\",\"\").replace(\"'\",\"\").replace(\")\",\"\").replace(\" \",\"\").replace(\",\",\"_\")\n",
    "#         df.rename({str(col):col_name},axis=1, inplace=True)\n",
    "#         print(df.columns)\n",
    "#     return df\n",
    "\n",
    "# rename columns\n",
    "def rename(col):\n",
    "    if isinstance(col, tuple):\n",
    "        col = '_'.join(str(c) for c in col)\n",
    "    return col\n",
    "\n",
    "def rename_df_col(df):\n",
    "    df.columns = map(rename, df.columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Made a new variable indicating whether the user making the querywas loacted in the country \n",
    "which was most common compared to the site (.jp, .com, etc.) or not\n",
    "'''\n",
    "# pandas according to two columns to find the max value\n",
    "site_country_id = df_all.groupby(['visitor_location_country_id', 'site_id'])['site_id'].agg('count').to_frame('site_country_cnt')\n",
    "site_country_id = site_country_id.loc[site_country_id.groupby('visitor_location_country_id').site_country_cnt.idxmax()]\n",
    "site_country_id.to_csv('data/site_country_common_id.csv')\n",
    "\n",
    "prop_feat_list = ['price_usd', 'prop_location_score1', 'prop_location_score2', 'prop_starrating', 'prop_review_score']\n",
    "'''\n",
    "Made a variable indicating the difference between the hotels price and the average\n",
    "price in the country it is in, need to do the difference in the next section\n",
    "'''\n",
    "prop_avg_price_country = df_all.groupby('prop_country_id')[prop_feat_list].agg(['mean', 'std', 'median']).fillna(0)\n",
    "prop_avg_price_country = rename_df_col(prop_avg_price_country)\n",
    "prop_avg_price_country.add_suffix('_ctry').to_csv('data/prop_avg_price_country.csv')\n",
    "\n",
    "\n",
    "'''\n",
    "Made a variable indicating the count of search destination id to show the popularity of one place, need to join in the next section\n",
    "'''\n",
    "srch_des_stat = df_all.groupby('srch_destination_id')[prop_feat_list].agg(['mean', 'std', 'median']).fillna(0)\n",
    "srch_des_cnt = df_all.groupby('srch_destination_id').agg({'srch_destination_id':'count'}).add_suffix('_cnt')\n",
    "srch_des_stat = rename_df_col(srch_des_stat)\n",
    "srch_des_cnt = srch_des_cnt.join(srch_des_stat.add_suffix('_dest'), on='srch_destination_id')\n",
    "srch_des_cnt.to_csv('data/srch_des_cnt.csv')\n",
    "\n",
    "'''\n",
    "Made a variable indicating the amount of searches for that point of time\n",
    "'''\n",
    "df_all['date_time'] = pd.to_datetime(df_all.date_time, format='%Y-%m-%d %H:%M:%S')\n",
    "df_all['year'] = df_all.date_time.dt.year\n",
    "df_all['month'] = df_all.date_time.dt.month\n",
    "df_all['day'] = df_all.date_time.dt.day\n",
    "df_all['hour'] = df_all.date_time.dt.hour\n",
    "df_all['dayofweek'] = df_all.date_time.dt.dayofweek\n",
    "\n",
    "date_list = ['month', 'day', 'hour', 'dayofweek']\n",
    "agg_list = ['click_bool', 'srch_id']\n",
    "names = locals()\n",
    "for i in date_list:\n",
    "    names['df_srch_hist' + str(i) ] = df_all.groupby(['prop_id', i])[agg_list].agg('count').add_prefix('hist_').add_suffix(f'_{i}')\n",
    "    names.get('df_srch_hist' + str(i)).to_csv(f'data/srch_hist_{i}.csv')\n",
    "\n",
    "'''\n",
    "Made a variable indicating how many searches there have been before per timepoint/year\n",
    "'''\n",
    "df_all['date_time_unix'] = (pd.to_datetime(df_all['date_time']) - pd.Timestamp('1970-01-01')) // pd.Timedelta('1s')\n",
    "df_srch_hist_timepoint = df_all.groupby(['prop_id', 'date_time_unix'])['prop_id'].sum().groupby(level=0).cumcount().to_frame('srch_hist_timepoint')\n",
    "df_srch_hist_timepoint.to_csv('data/srch_hist_date_time_unix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Made a lot of new variables\n",
    "'''\n",
    "# Aggregate the count of prop_id, promotion_flag and random_bool\n",
    "hotel_cnt = df_all.groupby('prop_id')['prop_id'].agg('count').to_frame('srch_count')\n",
    "hotel_pop = df_all.groupby('prop_id')[['promotion_flag', 'random_bool']].agg('sum')\n",
    "\n",
    "# We made some new variables which were averages, medians and standard deviations over the property-id’s. \n",
    "# The rationale behind computing these summary statistics over a property was mostly to lower the noise in the data.\n",
    "hotel_statistic = df_all.groupby('prop_id')[prop_feat_list].agg(['mean', 'std', 'median']).fillna(0)\n",
    "hotel_statistic = rename_df_col(hotel_statistic)\n",
    "\n",
    "# Variable mean of the position should exclude where the ordering was random\n",
    "random_mask = df_train.random_bool == 0\n",
    "position_feat = df_train[['prop_id', 'position']][random_mask].groupby('prop_id')['position'].agg(['mean','std','median']).add_prefix('position_').fillna(0)\n",
    "\n",
    "df_hotel_all = hotel_cnt.join(hotel_pop, on='prop_id')\n",
    "df_hotel_all = df_hotel_all.join(hotel_statistic.add_prefix('agg_'), on='prop_id')\n",
    "df_hotel_all = df_hotel_all.join(position_feat, on='prop_id')\n",
    "# df_hotel_all = fill_nan(df_hotel_all, 'median')\n",
    "df_hotel_all.to_csv('data/hotel_data_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['srch_count', 'promotion_flag', 'random_bool', 'agg_price_usd_mean',\n",
       "       'agg_price_usd_std', 'agg_price_usd_median',\n",
       "       'agg_prop_location_score1_mean', 'agg_prop_location_score1_std',\n",
       "       'agg_prop_location_score1_median', 'agg_prop_location_score2_mean',\n",
       "       'agg_prop_location_score2_std', 'agg_prop_location_score2_median',\n",
       "       'agg_prop_starrating_mean', 'agg_prop_starrating_std',\n",
       "       'agg_prop_starrating_median', 'agg_prop_review_score_mean',\n",
       "       'agg_prop_review_score_std', 'agg_prop_review_score_median',\n",
       "       'position_mean', 'position_std', 'position_median'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hotel_all.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-way count of the feature in only train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/training_cleaned.csv')\n",
    "df_train = pd.merge(df_train,df_orig_destination_distance, on=['visitor_location_country_id', 'prop_country_id'], how='left')\n",
    "df_train['orig_destination_distance'].fillna(df_train['orig_destination_distance_mean'], inplace=True)\n",
    "\n",
    "'''\n",
    "    Drop price_usd outliers for train set\n",
    "'''\n",
    "mask = df_train.prop_country_id.isin(df_country_outlier_id.prop_country_id.to_list())\n",
    "df_train.price_usd[mask] /= df_train.srch_length_of_stay[mask]\n",
    "drop_mask = (df_train.price_usd > 100000.0) | (df_train.price_usd == 0.0)\n",
    "df_train.drop(df_train[drop_mask].index, inplace=True)\n",
    "\n",
    "pred = df_train[['prop_location_score1', 'price_usd']].to_numpy()\n",
    "pred_y = reg_prop_location_score2.predict(pred)\n",
    "df_train['prop_location_score2_pred'] = pred_y\n",
    "df_train['prop_location_score2'].fillna(df_train['prop_location_score2_pred'], inplace=True)\n",
    "\n",
    "pred = df_train[['prop_starrating', 'prop_location_score1', 'prop_location_score2', 'price_usd', 'prop_brand_bool']].to_numpy()\n",
    "pred_y = reg_prop_review_score.predict(pred)\n",
    "df_train['prop_review_score_pred'] = pred_y\n",
    "df_train['prop_review_score'].fillna(df_train['prop_review_score_pred'], inplace=True)\n",
    "\n",
    "df_train.drop(columns=['orig_destination_distance_mean', 'prop_location_score2_pred', 'prop_review_score_pred'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                     4957546\n",
       "srch_id                        4957546\n",
       "date_time                      4957546\n",
       "site_id                        4957546\n",
       "visitor_location_country_id    4957546\n",
       "visitor_hist_starrating        4957546\n",
       "visitor_hist_adr_usd           4957546\n",
       "prop_country_id                4957546\n",
       "prop_id                        4957546\n",
       "prop_starrating                4957546\n",
       "prop_review_score              4957546\n",
       "prop_brand_bool                4957546\n",
       "prop_location_score1           4957546\n",
       "prop_location_score2           4957546\n",
       "prop_log_historical_price      4957546\n",
       "position                       4957546\n",
       "price_usd                      4957546\n",
       "promotion_flag                 4957546\n",
       "srch_destination_id            4957546\n",
       "srch_length_of_stay            4957546\n",
       "srch_booking_window            4957546\n",
       "srch_adults_count              4957546\n",
       "srch_children_count            4957546\n",
       "srch_room_count                4957546\n",
       "srch_saturday_night_bool       4957546\n",
       "srch_query_affinity_score       317377\n",
       "orig_destination_distance      4217622\n",
       "random_bool                    4957546\n",
       "comp2_rate                     2024317\n",
       "comp2_inv                      2129900\n",
       "comp3_rate                     1533997\n",
       "comp3_inv                      1650650\n",
       "comp5_rate                     2221863\n",
       "comp5_inv                      2359487\n",
       "comp8_rate                     1916427\n",
       "comp8_inv                      1987252\n",
       "click_bool                     4957546\n",
       "booking_bool                   4957546\n",
       "srch_hist_bool                 4957546\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible impute alternative, beware: SLOWWWW\n",
    "def KNN_impute(df):\n",
    "    col_names = df.columns\n",
    "    array = df.to_numpy()\n",
    "\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(array)\n",
    "    scaled = scaler.transform(array)\n",
    "\n",
    "    imputed_scaled = imputer.fit_transform(scaled)\n",
    "    imputed = scaler.inverse_transform(imputed_scaled)\n",
    "\n",
    "    return pd.DataFrame(imputed, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prop_id                             136885\n",
      "srch_count                          136885\n",
      "promotion_flag                      136885\n",
      "random_bool                         136885\n",
      "agg_price_usd_mean                  136885\n",
      "agg_price_usd_std                   136885\n",
      "agg_price_usd_median                136885\n",
      "agg_prop_location_score1_mean       136885\n",
      "agg_prop_location_score1_std        136885\n",
      "agg_prop_location_score1_median     136885\n",
      "agg_prop_location_score2_mean       136885\n",
      "agg_prop_location_score2_std        136885\n",
      "agg_prop_location_score2_median     136885\n",
      "agg_prop_starrating_mean            136885\n",
      "agg_prop_starrating_std             136885\n",
      "agg_prop_starrating_median          136885\n",
      "agg_prop_review_score_mean          136885\n",
      "agg_prop_review_score_std           136885\n",
      "agg_prop_review_score_median        136885\n",
      "position_mean                       119745\n",
      "position_std                        119745\n",
      "position_median                     119745\n",
      "booking_bool                        129111\n",
      "click_bool                          129111\n",
      "srch_query_affinity_score            52703\n",
      "srch_query_affinity_score_median     52703\n",
      "dtype: int64\n",
      "srch_query_affinity_score           136885\n",
      "srch_query_affinity_score_median    136885\n",
      "booking_bool                        136885\n",
      "click_bool                          136885\n",
      "promotion_flag                      136885\n",
      "random_bool                         136885\n",
      "srch_count                          136885\n",
      "agg_prop_review_score_mean          136885\n",
      "agg_price_usd_mean                  136885\n",
      "agg_prop_location_score1_mean       136885\n",
      "agg_prop_location_score2_mean       136885\n",
      "agg_price_usd_std                   136885\n",
      "agg_prop_location_score2_std        136885\n",
      "position_mean                       136885\n",
      "position_std                        136885\n",
      "position_median                     136885\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Create dataframe with aggregated hotel data here\n",
    "'''\n",
    "# Aggregate by sum and count\n",
    "hotel_pop = df_train.groupby('prop_id')[['booking_bool', 'click_bool']].agg('sum')\n",
    "srch_query_affinity_score_mean = df_train.groupby('prop_id')['srch_query_affinity_score'].agg('mean')\n",
    "srch_query_affinity_score_median = df_train.groupby('prop_id')['srch_query_affinity_score'].agg('median')\n",
    "\n",
    "# Aggregate by mean\n",
    "# hotel_feat = [feat for feat in list(df_train.columns) if 'prop' in feat] + ['srch_query_affinity_score'] \n",
    "df_hotel = pd.read_csv('data/hotel_data_all.csv')\n",
    "\n",
    "\n",
    "df_hotel = df_hotel.join(hotel_pop, on='prop_id')\n",
    "df_hotel = df_hotel.join(srch_query_affinity_score_mean, on='prop_id')\n",
    "df_hotel = df_hotel.join(srch_query_affinity_score_median, on='prop_id', rsuffix='_median')\n",
    "print(df_hotel.count())\n",
    "knn_list = ['srch_query_affinity_score', 'srch_query_affinity_score_median', 'booking_bool', 'click_bool', 'promotion_flag', 'random_bool', 'srch_count', \\\n",
    "     'agg_prop_review_score_mean', 'agg_price_usd_mean', 'agg_prop_location_score1_mean', 'agg_prop_location_score2_mean', \\\n",
    "     'agg_price_usd_std', 'agg_prop_location_score2_std', 'position_mean', 'position_std', 'position_median']\n",
    "df_knn = df_hotel[knn_list]\n",
    "\n",
    "# # Apply log(x + 1) transform \n",
    "# df_hotel['booking_bool'] = np.log(df_hotel['booking_bool'] + 1)\n",
    "# df_hotel['click_bool'] = np.log(df_hotel['click_bool'] + 1)\n",
    "df_knn_imp = KNN_impute(df_knn)\n",
    "print(df_knn_imp.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_query_affinity_score</th>\n",
       "      <th>srch_query_affinity_score_median</th>\n",
       "      <th>booking_bool</th>\n",
       "      <th>click_bool</th>\n",
       "      <th>promotion_flag</th>\n",
       "      <th>('prop_starrating', 'mean')</th>\n",
       "      <th>random_bool</th>\n",
       "      <th>srch_count</th>\n",
       "      <th>('prop_review_score', 'mean')</th>\n",
       "      <th>('price_usd', 'mean')</th>\n",
       "      <th>('prop_location_score1', 'mean')</th>\n",
       "      <th>('prop_location_score2', 'mean')</th>\n",
       "      <th>('price_usd', 'std')</th>\n",
       "      <th>('prop_location_score2', 'std')</th>\n",
       "      <th>position_mean</th>\n",
       "      <th>position_std</th>\n",
       "      <th>prop_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-46.171467</td>\n",
       "      <td>-38.32070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.960650</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.129791</td>\n",
       "      <td>10.161463</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>30.891304</td>\n",
       "      <td>5.900012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-22.589767</td>\n",
       "      <td>-24.09040</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>97.149655</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.066790</td>\n",
       "      <td>4.394746</td>\n",
       "      <td>0.165269</td>\n",
       "      <td>16.400000</td>\n",
       "      <td>3.777124</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-29.565475</td>\n",
       "      <td>-24.58075</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>117.853895</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.023659</td>\n",
       "      <td>96.052149</td>\n",
       "      <td>0.028234</td>\n",
       "      <td>20.238806</td>\n",
       "      <td>11.379260</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-34.197487</td>\n",
       "      <td>-34.74040</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>485.960952</td>\n",
       "      <td>4.88</td>\n",
       "      <td>0.150732</td>\n",
       "      <td>177.329762</td>\n",
       "      <td>0.047842</td>\n",
       "      <td>16.727273</td>\n",
       "      <td>8.295672</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-33.966717</td>\n",
       "      <td>-33.20363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>605.083654</td>\n",
       "      <td>6.02</td>\n",
       "      <td>0.266439</td>\n",
       "      <td>225.930093</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>24.384615</td>\n",
       "      <td>8.036774</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_query_affinity_score  srch_query_affinity_score_median  booking_bool  \\\n",
       "0                 -46.171467                         -38.32070           0.0   \n",
       "1                 -22.589767                         -24.09040           1.0   \n",
       "2                 -29.565475                         -24.58075           2.0   \n",
       "3                 -34.197487                         -34.74040           1.0   \n",
       "4                 -33.966717                         -33.20363           0.0   \n",
       "\n",
       "   click_bool  promotion_flag  ('prop_starrating', 'mean')  random_bool  \\\n",
       "0         1.0             0.0                          2.0         27.0   \n",
       "1         1.0             0.0                          0.0          3.0   \n",
       "2         2.0             1.0                          3.0         40.0   \n",
       "3         1.0            12.0                          5.0         20.0   \n",
       "4         2.0             3.0                          0.0         30.0   \n",
       "\n",
       "   srch_count  ('prop_review_score', 'mean')  ('price_usd', 'mean')  \\\n",
       "0       123.0                            0.0              94.960650   \n",
       "1        29.0                            4.0              97.149655   \n",
       "2       172.0                            3.5             117.853895   \n",
       "3        42.0                            4.5             485.960952   \n",
       "4        52.0                            0.0             605.083654   \n",
       "\n",
       "   ('prop_location_score1', 'mean')  ('prop_location_score2', 'mean')  \\\n",
       "0                              3.04                          0.129791   \n",
       "1                              0.69                          0.066790   \n",
       "2                              0.69                          0.023659   \n",
       "3                              4.88                          0.150732   \n",
       "4                              6.02                          0.266439   \n",
       "\n",
       "   ('price_usd', 'std')  ('prop_location_score2', 'std')  position_mean  \\\n",
       "0             10.161463                         0.000002      30.891304   \n",
       "1              4.394746                         0.165269      16.400000   \n",
       "2             96.052149                         0.028234      20.238806   \n",
       "3            177.329762                         0.047842      16.727273   \n",
       "4            225.930093                         0.000055      24.384615   \n",
       "\n",
       "   position_std  prop_id  \n",
       "0      5.900012        1  \n",
       "1      3.777124        2  \n",
       "2     11.379260        3  \n",
       "3      8.295672        4  \n",
       "4      8.036774        5  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_knn_imp['prop_id'] = df_hotel['prop_id']\n",
    "df_knn_imp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prop_id</th>\n",
       "      <th>srch_count</th>\n",
       "      <th>promotion_flag</th>\n",
       "      <th>random_bool</th>\n",
       "      <th>('prop_starrating', 'mean')</th>\n",
       "      <th>('prop_starrating', 'std')</th>\n",
       "      <th>('prop_starrating', 'median')</th>\n",
       "      <th>('prop_review_score', 'mean')</th>\n",
       "      <th>('prop_review_score', 'std')</th>\n",
       "      <th>('prop_review_score', 'median')</th>\n",
       "      <th>...</th>\n",
       "      <th>('prop_location_score2', 'median')</th>\n",
       "      <th>('price_usd', 'mean')</th>\n",
       "      <th>('price_usd', 'std')</th>\n",
       "      <th>('price_usd', 'median')</th>\n",
       "      <th>position_mean</th>\n",
       "      <th>position_std</th>\n",
       "      <th>booking_bool</th>\n",
       "      <th>click_bool</th>\n",
       "      <th>srch_query_affinity_score</th>\n",
       "      <th>srch_query_affinity_score_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129790</td>\n",
       "      <td>94.960650</td>\n",
       "      <td>10.161463</td>\n",
       "      <td>99.000</td>\n",
       "      <td>30.891304</td>\n",
       "      <td>5.900012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-46.171467</td>\n",
       "      <td>-38.32070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036100</td>\n",
       "      <td>97.149655</td>\n",
       "      <td>4.394746</td>\n",
       "      <td>97.000</td>\n",
       "      <td>16.400000</td>\n",
       "      <td>3.777124</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-22.589767</td>\n",
       "      <td>-24.09040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021933</td>\n",
       "      <td>117.853895</td>\n",
       "      <td>96.052149</td>\n",
       "      <td>100.000</td>\n",
       "      <td>20.238806</td>\n",
       "      <td>11.379260</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-29.565475</td>\n",
       "      <td>-24.58075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115500</td>\n",
       "      <td>485.960952</td>\n",
       "      <td>177.329762</td>\n",
       "      <td>434.725</td>\n",
       "      <td>16.727273</td>\n",
       "      <td>8.295672</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266443</td>\n",
       "      <td>605.083654</td>\n",
       "      <td>225.930093</td>\n",
       "      <td>589.550</td>\n",
       "      <td>24.384615</td>\n",
       "      <td>8.036774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   prop_id  srch_count  promotion_flag  random_bool  \\\n",
       "0        1         123               0           27   \n",
       "1        2          29               0            3   \n",
       "2        3         172               1           40   \n",
       "3        4          42              12           20   \n",
       "4        5          52               3           30   \n",
       "\n",
       "   ('prop_starrating', 'mean')  ('prop_starrating', 'std')  \\\n",
       "0                          2.0                         0.0   \n",
       "1                          0.0                         0.0   \n",
       "2                          3.0                         0.0   \n",
       "3                          5.0                         0.0   \n",
       "4                          0.0                         0.0   \n",
       "\n",
       "   ('prop_starrating', 'median')  ('prop_review_score', 'mean')  \\\n",
       "0                            2.0                            0.0   \n",
       "1                            0.0                            4.0   \n",
       "2                            3.0                            3.5   \n",
       "3                            5.0                            4.5   \n",
       "4                            0.0                            0.0   \n",
       "\n",
       "   ('prop_review_score', 'std')  ('prop_review_score', 'median')  ...  \\\n",
       "0                           0.0                              0.0  ...   \n",
       "1                           0.0                              4.0  ...   \n",
       "2                           0.0                              3.5  ...   \n",
       "3                           0.0                              4.5  ...   \n",
       "4                           0.0                              0.0  ...   \n",
       "\n",
       "   ('prop_location_score2', 'median')  ('price_usd', 'mean')  \\\n",
       "0                            0.129790              94.960650   \n",
       "1                            0.036100              97.149655   \n",
       "2                            0.021933             117.853895   \n",
       "3                            0.115500             485.960952   \n",
       "4                            0.266443             605.083654   \n",
       "\n",
       "   ('price_usd', 'std')  ('price_usd', 'median')  position_mean  position_std  \\\n",
       "0             10.161463                   99.000      30.891304      5.900012   \n",
       "1              4.394746                   97.000      16.400000      3.777124   \n",
       "2             96.052149                  100.000      20.238806     11.379260   \n",
       "3            177.329762                  434.725      16.727273      8.295672   \n",
       "4            225.930093                  589.550      24.384615      8.036774   \n",
       "\n",
       "   booking_bool  click_bool  srch_query_affinity_score  \\\n",
       "0           0.0         1.0                 -46.171467   \n",
       "1           1.0         1.0                 -22.589767   \n",
       "2           2.0         2.0                 -29.565475   \n",
       "3           1.0         1.0                        NaN   \n",
       "4           0.0         2.0                        NaN   \n",
       "\n",
       "   srch_query_affinity_score_median  \n",
       "0                         -38.32070  \n",
       "1                         -24.09040  \n",
       "2                         -24.58075  \n",
       "3                               NaN  \n",
       "4                               NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hotel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preserved prop_id with 0.00 % missing\n",
      "Preserved srch_count with 0.00 % missing\n",
      "Preserved promotion_flag with 0.00 % missing\n",
      "Preserved random_bool with 0.00 % missing\n",
      "Preserved agg_price_usd_mean with 0.00 % missing\n",
      "Preserved agg_price_usd_std with 0.00 % missing\n",
      "Preserved agg_price_usd_median with 0.00 % missing\n",
      "Preserved agg_prop_location_score1_mean with 0.00 % missing\n",
      "Preserved agg_prop_location_score1_std with 0.00 % missing\n",
      "Preserved agg_prop_location_score1_median with 0.00 % missing\n",
      "Preserved agg_prop_location_score2_mean with 0.00 % missing\n",
      "Preserved agg_prop_location_score2_std with 0.00 % missing\n",
      "Preserved agg_prop_location_score2_median with 0.00 % missing\n",
      "Preserved agg_prop_starrating_mean with 0.00 % missing\n",
      "Preserved agg_prop_starrating_std with 0.00 % missing\n",
      "Preserved agg_prop_starrating_median with 0.00 % missing\n",
      "Preserved agg_prop_review_score_mean with 0.00 % missing\n",
      "Preserved agg_prop_review_score_std with 0.00 % missing\n",
      "Preserved agg_prop_review_score_median with 0.00 % missing\n",
      "Preserved booking_bool with 5.68 % missing\n",
      "Preserved click_bool with 5.68 % missing\n",
      "Preserved position_mean with 0.00 % missing\n",
      "Preserved position_std with 0.00 % missing\n",
      "Preserved position_median with 0.00 % missing\n",
      "Preserved srch_query_affinity_score with 0.00 % missing\n",
      "Preserved srch_query_affinity_score_median with 0.00 % missing\n"
     ]
    }
   ],
   "source": [
    "df_knn_imp['prop_id'] = df_hotel['prop_id']\n",
    "df_knn_imp = df_knn_imp.set_index('prop_id')\n",
    "drop_list = ['position_mean', 'position_std', 'position_median', 'srch_query_affinity_score', 'srch_query_affinity_score_median']\n",
    "df_hotel_new = df_hotel.drop(columns=drop_list)\n",
    "df_hotel_new = df_hotel_new.join(df_knn_imp[drop_list], on='prop_id')\n",
    "for col in df_hotel_new.columns:\n",
    "    prc_nan = df_hotel_new[col].isnull().sum() / len(df_hotel_new[col])\n",
    "    print('Preserved {} with {:.2f} % missing'.format(col, prc_nan * 100))\n",
    "\n",
    "df_hotel_cnt = df_train.groupby('prop_id')['prop_id'].agg('count').to_frame('srch_cnt_single')\n",
    "df_hotel_new = df_hotel_new.join(df_hotel_cnt, on='prop_id').fillna(0)\n",
    "df_hotel_new['click_prob'] = (df_hotel_new['click_bool'] + 0.0001)/(df_hotel_new['srch_cnt_single'] + 0.0001)\n",
    "df_hotel_new['book_prob1'] = (df_hotel_new['booking_bool'] + 0.0001)/(df_hotel_new['click_bool'] + 0.0001)\n",
    "df_hotel_new['book_prob2'] = (df_hotel_new['booking_bool'] + 0.0001)/(df_hotel_new['srch_cnt_single'] + 0.0001)\n",
    "df_hotel_new.drop(columns=['srch_cnt_single'], inplace=True)\n",
    "df_hotel_new.to_csv('data/hotel_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further Clean Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def further_clean(df, dataset):\n",
    "\n",
    "    if dataset != 'train':\n",
    "        '''\n",
    "        Drop price_usd outliers\n",
    "        '''\n",
    "        df_country_outlier_id = pd.read_csv('data/price_outlier_country_id.csv')\n",
    "        mask = df.prop_country_id.isin(df_country_outlier_id.prop_country_id.to_list())\n",
    "        df.price_usd[mask] /= df.srch_length_of_stay[mask]\n",
    "    else:\n",
    "        df_country_outlier_id = pd.read_csv('data/price_outlier_country_id.csv')\n",
    "        mask = df.prop_country_id.isin(df_country_outlier_id.prop_country_id.to_list())\n",
    "        df.price_usd[mask] /= df.srch_length_of_stay[mask]\n",
    "        drop_mask = (df.price_usd > 100000.0) | (df.price_usd == 0.0)\n",
    "        df.drop(df[drop_mask].index, inplace=True)\n",
    "\n",
    "    df = pd.merge(df,df_orig_destination_distance, on=['visitor_location_country_id', 'prop_country_id'], how='left')\n",
    "    df['orig_destination_distance'].fillna(df['orig_destination_distance_mean'], inplace=True)\n",
    "\n",
    "    pred = df[['prop_location_score1', 'price_usd']].to_numpy()\n",
    "    pred_y = reg_prop_location_score2.predict(pred)\n",
    "    df['prop_location_score2_pred'] = pred_y\n",
    "    df['prop_location_score2'].fillna(df['prop_location_score2_pred'], inplace=True)\n",
    "\n",
    "    pred = df[['prop_starrating', 'prop_location_score1', 'prop_location_score2', 'price_usd', 'prop_brand_bool']].to_numpy()\n",
    "    pred_y = reg_prop_review_score.predict(pred)\n",
    "    df['prop_review_score_pred'] = pred_y\n",
    "    df['prop_review_score'].fillna(df['prop_review_score_pred'], inplace=True)\n",
    "\n",
    "    df.drop(columns=['orig_destination_distance_mean', 'prop_location_score2_pred', 'prop_review_score_pred', 'srch_query_affinity_score'], inplace=True)\n",
    "\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                     4957546\n",
      "srch_id                        4957546\n",
      "date_time                      4957546\n",
      "site_id                        4957546\n",
      "visitor_location_country_id    4957546\n",
      "visitor_hist_starrating        4957546\n",
      "visitor_hist_adr_usd           4957546\n",
      "prop_country_id                4957546\n",
      "prop_id                        4957546\n",
      "prop_starrating                4957546\n",
      "prop_review_score              4957546\n",
      "prop_brand_bool                4957546\n",
      "prop_location_score1           4957546\n",
      "prop_location_score2           4957546\n",
      "prop_log_historical_price      4957546\n",
      "position                       4957546\n",
      "price_usd                      4957546\n",
      "promotion_flag                 4957546\n",
      "srch_destination_id            4957546\n",
      "srch_length_of_stay            4957546\n",
      "srch_booking_window            4957546\n",
      "srch_adults_count              4957546\n",
      "srch_children_count            4957546\n",
      "srch_room_count                4957546\n",
      "srch_saturday_night_bool       4957546\n",
      "orig_destination_distance      4957546\n",
      "random_bool                    4957546\n",
      "comp2_rate                     4957546\n",
      "comp2_inv                      4957546\n",
      "comp3_rate                     4957546\n",
      "comp3_inv                      4957546\n",
      "comp5_rate                     4957546\n",
      "comp5_inv                      4957546\n",
      "comp8_rate                     4957546\n",
      "comp8_inv                      4957546\n",
      "click_bool                     4957546\n",
      "booking_bool                   4957546\n",
      "srch_hist_bool                 4957546\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/training_cleaned.csv')\n",
    "# clean train set\n",
    "df_train_cleaned = further_clean(df_train, 'train')\n",
    "print(df_train_cleaned.count())\n",
    "df_train_cleaned.to_csv('data/train_cleaned_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                     4959183\n",
      "srch_id                        4959183\n",
      "date_time                      4959183\n",
      "site_id                        4959183\n",
      "visitor_location_country_id    4959183\n",
      "visitor_hist_starrating        4959183\n",
      "visitor_hist_adr_usd           4959183\n",
      "prop_country_id                4959183\n",
      "prop_id                        4959183\n",
      "prop_starrating                4959183\n",
      "prop_review_score              4959183\n",
      "prop_brand_bool                4959183\n",
      "prop_location_score1           4959183\n",
      "prop_location_score2           4959183\n",
      "prop_log_historical_price      4959183\n",
      "price_usd                      4959183\n",
      "promotion_flag                 4959183\n",
      "srch_destination_id            4959183\n",
      "srch_length_of_stay            4959183\n",
      "srch_booking_window            4959183\n",
      "srch_adults_count              4959183\n",
      "srch_children_count            4959183\n",
      "srch_room_count                4959183\n",
      "srch_saturday_night_bool       4959183\n",
      "orig_destination_distance      4959183\n",
      "random_bool                    4959183\n",
      "comp2_rate                     4959183\n",
      "comp2_inv                      4959183\n",
      "comp3_rate                     4959183\n",
      "comp3_inv                      4959183\n",
      "comp5_rate                     4959183\n",
      "comp5_inv                      4959183\n",
      "comp8_rate                     4959183\n",
      "comp8_inv                      4959183\n",
      "srch_hist_bool                 4959183\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('data/test_cleaned.csv')\n",
    "# clean test set\n",
    "df_test_cleaned = further_clean(df_test, 'test')\n",
    "print(df_test_cleaned.count())\n",
    "df_test_cleaned.to_csv('data/test_cleaned_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>visitor_hist_starrating</th>\n",
       "      <th>visitor_hist_adr_usd</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>...</th>\n",
       "      <th>comp6_rate_percent_diff</th>\n",
       "      <th>comp7_rate</th>\n",
       "      <th>comp7_inv</th>\n",
       "      <th>comp7_rate_percent_diff</th>\n",
       "      <th>comp8_rate</th>\n",
       "      <th>comp8_inv</th>\n",
       "      <th>comp8_rate_percent_diff</th>\n",
       "      <th>click_bool</th>\n",
       "      <th>gross_bookings_usd</th>\n",
       "      <th>booking_bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>47</td>\n",
       "      <td>2013-01-14 22:28:43</td>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "      <td>4.31</td>\n",
       "      <td>180.75</td>\n",
       "      <td>137</td>\n",
       "      <td>6618</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>47</td>\n",
       "      <td>2013-01-14 22:28:43</td>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "      <td>4.31</td>\n",
       "      <td>180.75</td>\n",
       "      <td>137</td>\n",
       "      <td>11747</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>47</td>\n",
       "      <td>2013-01-14 22:28:43</td>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "      <td>4.31</td>\n",
       "      <td>180.75</td>\n",
       "      <td>137</td>\n",
       "      <td>18311</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>47</td>\n",
       "      <td>2013-01-14 22:28:43</td>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "      <td>4.31</td>\n",
       "      <td>180.75</td>\n",
       "      <td>137</td>\n",
       "      <td>19599</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>47</td>\n",
       "      <td>2013-01-14 22:28:43</td>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "      <td>4.31</td>\n",
       "      <td>180.75</td>\n",
       "      <td>137</td>\n",
       "      <td>24002</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     srch_id            date_time  site_id  visitor_location_country_id  \\\n",
       "550       47  2013-01-14 22:28:43       14                          100   \n",
       "551       47  2013-01-14 22:28:43       14                          100   \n",
       "552       47  2013-01-14 22:28:43       14                          100   \n",
       "553       47  2013-01-14 22:28:43       14                          100   \n",
       "554       47  2013-01-14 22:28:43       14                          100   \n",
       "\n",
       "     visitor_hist_starrating  visitor_hist_adr_usd  prop_country_id  prop_id  \\\n",
       "550                     4.31                180.75              137     6618   \n",
       "551                     4.31                180.75              137    11747   \n",
       "552                     4.31                180.75              137    18311   \n",
       "553                     4.31                180.75              137    19599   \n",
       "554                     4.31                180.75              137    24002   \n",
       "\n",
       "     prop_starrating  prop_review_score  ...  comp6_rate_percent_diff  \\\n",
       "550                3                4.0  ...                      NaN   \n",
       "551                4                4.5  ...                      NaN   \n",
       "552                4                4.0  ...                      NaN   \n",
       "553                3                4.0  ...                      NaN   \n",
       "554                4                4.5  ...                      NaN   \n",
       "\n",
       "     comp7_rate  comp7_inv  comp7_rate_percent_diff  comp8_rate  comp8_inv  \\\n",
       "550         NaN        1.0                      NaN         NaN        NaN   \n",
       "551         NaN        NaN                      NaN         NaN        NaN   \n",
       "552         NaN        NaN                      NaN         NaN        NaN   \n",
       "553         NaN        1.0                      NaN         NaN        NaN   \n",
       "554         NaN        NaN                      NaN         NaN        NaN   \n",
       "\n",
       "     comp8_rate_percent_diff  click_bool  gross_bookings_usd  booking_bool  \n",
       "550                      NaN           0                 NaN             0  \n",
       "551                      NaN           0                 NaN             0  \n",
       "552                      NaN           0                 NaN             0  \n",
       "553                      NaN           0                 NaN             0  \n",
       "554                      NaN           0                 NaN             0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check same srch_id same visitor_hist_adr_usd\n",
    "df_train[~df_train['visitor_hist_adr_usd'].isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preserved srch_query_affinity_score with 93.60 % missing\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    prc_nan = df[col].isnull().sum() / len(df[col])\n",
    "    if prc_nan != 0.0:\n",
    "        print('Preserved {} with {:.2f} % missing'.format(col, prc_nan * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_srch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/willem/Documents/CS/Data_Mining/DMT_2/preprocessing.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/willem/Documents/CS/Data_Mining/DMT_2/preprocessing.ipynb#ch0000006?line=0'>1</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/willem/Documents/CS/Data_Mining/DMT_2/preprocessing.ipynb#ch0000006?line=1'>2</a>\u001b[0m \u001b[39mBalance dataset here. \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/willem/Documents/CS/Data_Mining/DMT_2/preprocessing.ipynb#ch0000006?line=2'>3</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/willem/Documents/CS/Data_Mining/DMT_2/preprocessing.ipynb#ch0000006?line=3'>4</a>\u001b[0m \u001b[39m# df_srch = df.join(df_hotel['srch_count'].to_frame('srch_count'), on='prop_id')\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/willem/Documents/CS/Data_Mining/DMT_2/preprocessing.ipynb#ch0000006?line=4'>5</a>\u001b[0m df_srch\u001b[39m.\u001b[39mquery(\u001b[39m'\u001b[39m\u001b[39msrch_count > 4.75 | click_bool == 1\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_srch' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Balance dataset here. \n",
    "'''\n",
    "# df_srch = df.join(df_hotel['srch_count'].to_frame('srch_count'), on='prop_id')\n",
    "df_srch.query('srch_count > 4.75 | click_bool == 1')\n",
    "\n",
    "\n",
    "X_train = df.to_numpy()[:, :-1]\n",
    "y_train = df.to_numpy()[:, -1]\n",
    "\n",
    "smt = SMOTETomek(ratio='auto')\n",
    "X_smt, y_smt = smt.fit_sample(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f775358a36c1bda3b4c58ec845d9881063e3e00360351ef98798feb093e44f29"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
